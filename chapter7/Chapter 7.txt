7.0 Scheduling: Introduction
- High-level scheduling policies are somtimes called disciplines.

7.1 Workload Assumptions
- Workload: Processes running in the system
- Goal: A fully-operational-scheduling discipline
- Assumptions for jobs (Processes):
  - Each jobs runs for the same amount of time.
  - All jobs arrive at the same time.
  - Once started, each job runs to completions.
  - All jobs only usse the CPU (no I/O).
  - The run-time of each job is known.

7.2 Scheduling Metrics
- A scheduling metric is used to compare different scheduling policies.
- A metric is something to measure something, there are many that make sense in scheduling.
- Turnaround time: A metric that measures the time of a job it completes minus the time it arrives:
  T(turnaround) = T(completion) - T(arrival)
- As all jobs arrive at the same time: T(arrival) = 0 and T(turnaround) = T(completion).
- The turnaround time is a performance metric.
- Fairness is another metric of interest. A scheduler could optimize performance but at the cost of preventing a few jobs.

7.3 First In, First Out (FIFO)
- Simple and easy to implement: First In, First Out (FIFO)/First Come, First Served (FCFS)
- Example: Jobs A, B, C arrive at roughly the same time, but with A before B and B before C. All processes take 10 seconds.
  - The turnaround time for A will be 10 seconds, for B 20 seconds and for C 30 seconds:
  - The average turnaround time will be: (10 + 20 + 30)/3 = 20.
  - If A runs 100 seconds instead of 10, the average turnaround time is increased to 110.
    - This describes the convoy effect: Relatives-short resource consumers are queued behind a heavyweight resource consumer.
- Shortes Job First (SJF) is like a "ten-item-or-less" line in a grocery store and is used where turnaround time matters.

7.4 Shortest Job First (SJF)
- The shortes job is first ran, then the next shortest, and so on.
- With the example of 7.3, the average turnaround time is decreased to 50.
- Non-preemptive schedulers: Each job is run to completions before it is considered whether to run a new job.
- All modern schedulers are preemptive and will stop one process to run another, the scheduler can perform a context switch.
- If all processes do not arrive at the same time anymore, with A arriving at t = 0, running 100 seconds, and B and C arriving at t = 10 and running for 10 seconds, B and C will suffer a convoy problem with SJF.
  - The average turnaround time is 103.33 seconds: (100+(110-10)+(120-10))/3 = 103.33.

7.5 Shortest Time-to-Completion First (STCF)
- To improve average turnaround time, jobs do not have to run to completion anymore.
- The scheduler can preempt job A when B and C arrive and run them and can later continue A.
- Preemption added to SJF: Shortest Time-to-Completion First (STCF)/Preemptive Shortest Job First (PSJF)
- Everytime a new job arrives, the scheduler runs the job that has the least time left.
- The turnaround time is decreased to 50 seconds.

7.6 A New Metric: Response Time
- Response time started mattering when time-shared machines arrived.
- It is defined as: T(response) = T(firstrun) - T(arrival)
- With the example from 7.5, the response time is 0 for A and B and 10 for C. The average response time is 3.33.
- If three jobs with the same completion time arrive at the same time, the third job will have to wait for the first and second to complete.

7.7 Round Robin
- Round Robin (RR) runs a job for a time slice (also called a scheduling quantum) instead of running a job to completion and then switches to the next job in the run queue. This is repated until all jobs are finished.
- RR is sometimes called time-slicing.
- The length of a time slice must be a multiple of the timer-interrupt period.
- Amortization is used in systems with a fixed cost to an operation. By performing the operation fewer times, the total cost is reduced. If the time slice is set to 10 ms and the context-switch cost is 1 ms, the context-switch wastes 10% of time. By increasing the time slice to 100 ms, the context switch only takes 1% of time. The cost of time-slicing has been amortized.
- With three jobs A, B and C arriving at the same time and each wishing to run for 5 seconds, the average response time of RR is (0+1+2)/3 = 1. With SJF, it would be (0+5+10)/3 = 5.
- The shorter the time slice, the better is the response-time under RR.
- A time slice too short will make the cost of context switching dominate performance. The time slice has to be long enough to amortize the cost of context switching without making it too long so that the system is unresponsive.
- The cost of context switching does not only arise from the OS by saving and restoring registers, but also from CPU caches, TLBs, branch predictors and other on-chip hardware. Switching the job causes this state to be flushed and a new state relevant to the currently-running process to be brought in which may be a noticeable perfomance cost.
- RR is one of the worst policies if it comes to turnaround time. A, B and C have an average response time of 14.
- Any policy that is fair (such as RR) will perform poorly on turnaround time. If the policy is unfair, shorter jobs can be ran to completion at the cost of response time. If the policy is fair, response time is lowered at the cost of turnaround time. This trade-off is common in systems.
- SJF and STCF optimize turnaround time while RR optimizes response time.

7.8 Incorporating I/O
- During I/O, the currently-running job will not use the CPU and is blocked waiting for the I/O completions, so the scheduler should schedule another job on the CPU.
- When the I/O is completed, an interrupt is raised and the process is moved from blocked to ready state. The OS could decide to run that process right away.
- With a STCF scheduler, two jobs A and B, where A and B use the CPU for 50 ms, but A issues an I/O request after 10 ms which takes 10 ms, then uses the CPU for 10 ms again, then issues an I/O request again and so on:
  - A is broken up into 5 10-ms sub-jobs. Each sub-job is treated as an independent job.
  - STCF will choose the shorter job, which is A.
  - When the first sub-job has completed, only B is left and begins running.
  - When A finishes the first I/O request, a new sub-job of A is submitted and it preempts B and runs for 10 ms. 
  - This allows overlap: The CPU is being used by one process while waiting for the I/O of another process to complete.
  - By treating each CPU burst as a job, the scheduler makes sure that process which are "interactive" are ran frequently. While they are performing I/O, the CPU can be used by CPU-intensive jobs, so the CPU is better utilized.

7.9
- In a general-purpose OS, very little is known about the processes. It is unrealistic that the OS knows the length of each process.

7.10
- A scheduler that uses the recent past to predict the future so it can solve the problem of not known the length of each process is known as the multi-level feedback queue.
