8.0 Scheduling: The Multi-Level Feedback Queue
- The Multi-level Feedback Queue (MLFQ) tries to optimize turnaround time and response time without knowing how long a process will run.
- MLFQ is an example of a system that learns from the past to predict the future.
  - It works when jobs have phases of behavior which make them predictable.
  - Such techniques can lead to worse decisions than not knowing anything at all. One must be careful.

8.1 MLFQ: Basic Rules
- The specifics of many MLFQ implementations differ but most approaches are similar.
- There are distinc queues with a different priority level. A job that is ready to run is on a single queue.
  - The priorities are used to decide which job to run. A job with higher priority (on a queue with higher priority) is chosen to run.
  - If there are multiple jobs on a queue, round-robin scheduling is used among them.
  => Rule 1: If Priority(A) > Priority(B), A runs (B does not).
  => Rule 2: If Priority(A) = Priority(B), A & B run in RR.
- Priorites of job are varied based on their behavior observed. They are not fixed.
  - If a job repeatedly does not use the CPU as it is waiting for keyboard input, its priority is kept high.
  - If a job uses the CPU intensively for long periods of time, its priority is reduced.
  - MLFQ uses the history of the job to learn about it and predict its future behaviour.

8.2 Attempt #1: How To Change Priority
- Workload: A mix of interative short-running jobs and longer-running CPU-intensive jobs.
- The priority of a job will be changed based on its allotment: The amount of time a job can spend at a given priority level before it is reduced by the scheduler. For simplicity, the allotment will be equal to a single time slice:
  => Rule 3: When a job enters the system, it is placed at the highest priority.
  => Rule 4a: If a job uses up its allotment while running, its priority is reduced.
  => Rule 4b: If a job gives up the CPU before the allotment is up, it stays at the same priority level. Its allotment is reset.
- Example 1: A Single Long-Running Job
  - A long-running job with a time slice and allotment to 10 ms will have its priority reduced every 10 ms.
  - In a three-queue scheduler, it enters at the highest queue and will end up in the lowest queue after 20 ms.
- Example 2: Along Came A Short Job
  - A is a long-running CPU-intensive job and has been running for some time and is therefore in the lowest-priority queue.
  - B arrives and is inserted into the highest queue. It has a short run-time of 20 ms so it can complete before reaching the bottom queue, in two time slices.
  - After B, A can resume.
  - The example shows on of the main goal of the algorithm. As it does not know the length of a job, it first assumes it might be a short job. If it is actually a short, it will run quickly and complete. If it is not, it will slowly move down the queues.
- Example 3: What About I/O?
  - With an interactive job B that needs the CPU only for 1 ms before performing I/O and a long-running batch job A, B is kept at the highest priority as it keeps releasing the CPU.
  - That way, MLFQ archives its goal by running interactive jobs quickly.
- Problems With Our Current MLFQ
  - Starvation: If there are too many interactive jobs, they will combine to consume the CPU all time. Long-running jobs will never receive any CPU and starve.
  - Gaming the scheduler: A process could trick the scheduler by issuing an I/O operation before the allotment is used to remain in the same queue. A job could nearly monopolize the CPU that way.
  - A scheduling policy is a security concern in many cases as - without care in policy design and enforcement - a single user may be able to adversely harm others and gain advantage for itself.

8.3 Attempt #2: The Priority Boost
