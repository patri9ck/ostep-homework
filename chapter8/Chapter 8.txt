8.0 Scheduling: The Multi-Level Feedback Queue
- The Multi-level Feedback Queue (MLFQ) tries to optimize turnaround time and response time without knowing how long a process will run.
- MLFQ is an example of a system that learns from the past to predict the future.
  - It works when jobs have phases of behavior which make them predictable.
  - Such techniques can lead to worse decisions than not knowing anything at all. One must be careful.

8.1 MLFQ: Basic Rules
- The specifics of many MLFQ implementations differ but most approaches are similar.
- There are distinc queues with a different priority level. A job that is ready to run is on a single queue.
  - The priorities are used to decide which job to run. A job with higher priority (on a queue with higher priority) is chosen to run.
  - If there are multiple jobs on a queue, round-robin scheduling is used among them.
  => Rule 1: If Priority(A) > Priority(B), A runs (B does not).
  => Rule 2: If Priority(A) = Priority(B), A & B run in RR.
- Priorites of job are varied based on their behavior observed. They are not fixed.
  - If a job repeatedly does not use the CPU as it is waiting for keyboard input, its priority is kept high.
  - If a job uses the CPU intensively for long periods of time, its priority is reduced.
  - MLFQ uses the history of the job to learn about it and predict its future behaviour.

8.2 Attempt #1: How To Change Priority
- Workload: A mix of interative short-running jobs and longer-running CPU-intensive jobs.
- The priority of a job will be changed based on its allotment: The amount of time a job can spend at a given priority level before it is reduced by the scheduler. For simplicity, the allotment will be equal to a single time slice:
  => Rule 3: When a job enters the system, it is placed at the highest priority.
  => Rule 4a: If a job uses up its allotment while running, its priority is reduced.
  => Rule 4b: If a job gives up the CPU before the allotment is up, it stays at the same priority level. Its allotment is reset.
- Example 1: A Single Long-Running Job
  - A long-running job with a time slice and allotment to 10 ms will have its priority reduced every 10 ms.
  - In a three-queue scheduler, it enters at the highest queue and will end up in the lowest queue after 20 ms.
- Example 2: Along Came A Short Job
  - A is a long-running CPU-intensive job and has been running for some time and is therefore in the lowest-priority queue.
  - B arrives and is inserted into the highest queue. It has a short run-time of 20 ms so it can complete before reaching the bottom queue, in two time slices.
  - After B, A can resume.
  - The example shows on of the main goal of the algorithm. As it does not know the length of a job, it first assumes it might be a short job. If it is actually a short, it will run quickly and complete. If it is not, it will slowly move down the queues.
- Example 3: What About I/O?
  - With an interactive job B that needs the CPU only for 1 ms before performing I/O and a long-running batch job A, B is kept at the highest priority as it keeps releasing the CPU.
  - That way, MLFQ archives its goal by running interactive jobs quickly.
- Problems With Our Current MLFQ
  - Starvation: If there are too many interactive jobs, they will combine to consume the CPU all time. Long-running jobs will never receive any CPU and starve.
  - Gaming the scheduler: A process could trick the scheduler by issuing an I/O operation before the allotment is used to remain in the same queue. A job could nearly monopolize the CPU that way.
  - A scheduling policy is a security concern in many cases as - without care in policy design and enforcement - a single user may be able to adversely harm others and gain advantage for itself.

8.3 Attempt #2: The Priority Boost
- To avoid starvation, the priority of all jobs could be boosted periodically.
  => Rule 5: After some time period S, move all the jobs in the system to the topmost queue.
- Two problems are solved that way:
  1. Processes are guaranteed not to starve.
  2. If a CPU-bound job becomes interactive, it will be treated properly by the scheduler once it has received the priority boost.
- Example: A long-running job competing for the CPU with two short-running job will get a priority boost every 100 ms and will therefore get to run every 100 ms periodically.
- What should S be set to?
  - If S is set too high, long-running jobs could starve.
  - If S is set too low, interactive jobs may not get a proper share of the CPU.

8.4 Attempt #3: Better Accounting
- How to prevent gaming of the scheduler? Instead of forgetting how much of its allotment the process used, it should keep track of it. Once a process has used it, it is demoted to the next priority queue. Rule 4a and 4b are rewritten to:
  => Rule 4: Once a job uses up its time allotment at a given level, regardless of how many times it has given up the CPU, its priority is reduced.

8.5 Tuning MLFQ And Other Issues
- How to parameterize such a scheduler?
  - How many queues?
  - How big should the time slice be per queue?
  - How big should the allotment be?
  - How often should the priority be boosted?
- High priority queues often have a short time slice of 10 or fewer milliseconds as they are compromised of interactive jobs, so alternatving quickly between them makes sense.
- Low priority queues have longer time slices like 100 ms as they contain long-running jobs that are CPU-bound.
- The Solaris MLFQ implementation/Time-Sharing scheduling class/TS is configured through a set of tables that determine exactly how the priority of a process is altered, how long each time slice is and how often the priority of a job is boosted.
  - Administrators can edit this table to make the scheduler behave in different ways.
  - Default values for the table are 60 queues, with increasing time-slice length from 20 milliseconds for the highest priority to a few hundred milliseconds for the lowest priority. Priorities are boosted around every 1 second.
- FreeBSD uses a formula to calculate the current priority level of a job based of how much CPU the process has used. Such a decay-usage algorithm decays the usage over time, the desired priority boost is provided differently.
- Some operating systems reserve the highest priority level for operating system work, user jobs can never obtain them.
- With the command utility nice, some systems allow the user to increase or decrease the priority of a job somewhat.
- As the OS does not know what is best for each process, it is useful to provide interfaces to allows users to provide hints to the OS. Those Hints are often called advice, which might be taken by the OS into account to make a better decision.

8.6 MLFQ: Summary
- MLFQ has multiple levels of queues and uses feedback to determine the priority of a given job.
=> Rule 1: If Priority(A) > Priority(B), A runs (B does not).
=> Rule 2: If Priority(A) = Priority(B), A & B run in RR.
=> Rule 3: When a job enters the system, it is placed at the highest priority.
=> Rule 4: Once a job uses up its time allotment at a given level, regardless of how many times it has given up the CPU, its priority is reduced
=> Rule 5: After some time period S, move all the jobs in the system to the topmost queue.
